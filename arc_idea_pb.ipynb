{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from examples.iris import IrisDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "rnd = np.random.RandomState(seed=13)\n",
    "n_units = 100\n",
    "n_in = 4\n",
    "n_out = 3\n",
    "\n",
    "csv_path = \"./examples/\"\n",
    "dataset = IrisDataset(csv_path=csv_path, seed=12)\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, n_in), name=\"ExternalInput\")\n",
    "W_init = rnd.normal(size=(n_in, n_units), loc=0, scale=.01)\n",
    "b_init = np.zeros(shape=(n_units,))\n",
    "W = tf.Variable(initial_value=W_init, name='W', dtype=tf.float32)\n",
    "b = tf.Variable(initial_value=b_init, name='b', dtype=tf.float32)\n",
    "a = tf.matmul(x, W) + b\n",
    "h = tf.tanh(a)\n",
    "W_out_init = rnd.normal(size=(n_units, n_out), loc=0, scale=.01)\n",
    "W_out = tf.Variable(initial_value=W_out_init, name='W_out', dtype=tf.float32)\n",
    "\n",
    "b_out_init = np.zeros(shape=(n_out,))\n",
    "b_out = tf.Variable(initial_value=b_out_init, name='b_out', dtype=tf.float32)\n",
    "y = tf.matmul(h, W_out) + b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# task\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out], name=\"labels\")  # labels\n",
    "loss = -tf.reduce_sum(t * tf.log(y), reduction_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training step\n",
    "alpha = 0.001\n",
    "gW_out, gb_out = tf.gradients(loss, [W_out, b_out])\n",
    "gh = tf.gradients(loss, h)[0]\n",
    "h_1 = h - alpha * gh\n",
    "\n",
    "# a_star = a  # TODO\n",
    "cutoff = 0.99\n",
    "\n",
    "\n",
    "def arctanh(x):\n",
    "    return (tf.log(1 + x) - tf.log(1 - x)) / 2\n",
    "\n",
    "a_star = tf.where(tf.logical_and(h_1 > h, h > cutoff), a,\n",
    "                  tf.where(tf.logical_and(h_1 < h, h < -cutoff), a, arctanh(h_1)))\n",
    "\n",
    "d = a_star - a\n",
    "\n",
    "ga_W_in, ga_b_in = tf.gradients(tf.reduce_mean((a - a_star) ** 2, axis=0), [W, b])\n",
    "# ga_W_in, ga_b_in = tf.gradients(loss, [W, b])\n",
    "\n",
    "grad_var_pairs = ((gW_out, W_out), (gb_out, b_out), (ga_b_in, b), (ga_W_in, W))\n",
    "grads = [tf.reshape(g[0], [-1]) for g in grad_var_pairs]\n",
    "gradient = tf.concat(grads, 0)\n",
    "\n",
    "clipped_grads, _ = tf.clip_by_global_norm(grads, clip_norm=1)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha)\n",
    "train_op = optimizer.apply_gradients(grad_var_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = open('/dev/stdout', 'w')\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "validation_batch = dataset.get_validation()\n",
    "test_batch = dataset.get_test()\n",
    "\n",
    "print(\"Training...\")\n",
    "for i in range(300):\n",
    "    batch = dataset.get_batch(batch_size)\n",
    "    feed_dict = {x: batch[\"input\"], t: batch[\"output\"]}\n",
    "    _, grad_norm = sess.run((train_op, tf.reduce_sum(tf.reduce_sum(gradient**2))), feed_dict=feed_dict)\n",
    "    if i % 100 == 0:\n",
    "        y_np = sess.run(y, feed_dict={x: validation_batch[\"input\"], t: validation_batch[\"output\"]})\n",
    "        acc = accuracy_score(y_true=np.argmax(validation_batch[\"output\"], axis=1), y_pred=np.argmax(y_np, axis=1))\n",
    "        # print(\"Val accuracy score: {:.2f}\".format(acc))\n",
    "\n",
    "        print('Iteration {} -> val error:{:.2f}, g_norm: {:.2f}'.format(i, acc, grad_norm))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_np = sess.run(y, feed_dict={x: test_batch[\"input\"]})\n",
    "\n",
    "score = accuracy_score(y_true=np.argmax(dataset.get_test()[\"output\"], axis=1), y_pred=np.argmax(y_np, axis=1))\n",
    "sess.close()\n",
    "print(\"Test accuracy score: {:.2f}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
